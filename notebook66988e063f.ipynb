{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install -q langchain langchain-community langchain_huggingface chromadb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:26:19.369488Z","iopub.execute_input":"2025-01-23T07:26:19.370017Z","iopub.status.idle":"2025-01-23T07:26:24.375243Z","shell.execute_reply.started":"2025-01-23T07:26:19.369962Z","shell.execute_reply":"2025-01-23T07:26:24.373791Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"## 1. Use langchain RAG¶","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:01:25.901202Z","iopub.execute_input":"2025-01-23T07:01:25.901683Z","iopub.status.idle":"2025-01-23T07:01:25.907025Z","shell.execute_reply.started":"2025-01-23T07:01:25.901646Z","shell.execute_reply":"2025-01-23T07:01:25.905707Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import os\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.vectorstores import Chroma\nfrom langchain.chains import RetrievalQA\nfrom langchain.prompts import PromptTemplate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:35:36.866610Z","iopub.execute_input":"2025-01-23T06:35:36.866972Z","iopub.status.idle":"2025-01-23T06:35:36.872615Z","shell.execute_reply.started":"2025-01-23T06:35:36.866946Z","shell.execute_reply":"2025-01-23T06:35:36.871087Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"YOUR-API-KEY\"  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:35:42.042942Z","iopub.execute_input":"2025-01-23T06:35:42.043346Z","iopub.status.idle":"2025-01-23T06:35:42.049011Z","shell.execute_reply.started":"2025-01-23T06:35:42.043319Z","shell.execute_reply":"2025-01-23T06:35:42.047695Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"from langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.llms import HuggingFaceHub\n\n# set Korean embedding and llm odel\nhf_embeddings = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")\n\nhf_llm = HuggingFaceHub(\n    repo_id=\"skt/kogpt2-base-v2\",\n    model_kwargs={\"task\": \"text-generation\"} ## question-answering tasK X. text-generation\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:35:45.770743Z","iopub.execute_input":"2025-01-23T06:35:45.771151Z","iopub.status.idle":"2025-01-23T06:35:47.240966Z","shell.execute_reply.started":"2025-01-23T06:35:45.771124Z","shell.execute_reply":"2025-01-23T06:35:47.238898Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"import requests\nfrom langchain.schema import Document\nfrom bs4 import BeautifulSoup\n\n# for Wikipedia documents (EN, KO)\n\n# from langchain_community.document_loaders import WikipediaLoader\n\n# By default, English documents (https://en.wikipedia.org))\n# def load_Wiki_docs(query):\n#     loader = WikipediaLoader(query=query, load_max_docs=1) # need !pip install wikipedia\n#     documents = loader.load()\n    \n#     text_splitter = RecursiveCharacterTextSplitter(\n#         chunk_size=1000,\n#         chunk_overlap=200\n#     )\n#     splits = text_splitter.split_documents(documents)\n    \n#     return splits\n\n\n# For Korean query, get results from Korean wikipedia website and crawl and parse results\ndef load_Korean_wiki_docs(topic):\n    url = f\"https://ko.wikipedia.org/wiki/{topic}\"\n    \n    response = requests.get(url)\n    response.raise_for_status()  # raise Exception when error occurs\n\n    # HTML parsing and extract body contents\n    soup = BeautifulSoup(response.text, 'html.parser')\n    content = soup.find('div', {'class': 'mw-parser-output'})  # find div including body contents \n    \n    # Extract contents\n    paragraphs = content.find_all('p')\n    text = \"\\n\".join([p.get_text() for p in paragraphs])  # concat all context in <p> tags \n \n    # convert to Document object (required for LangChain)\n    documents = [Document(page_content=text, metadata={\"source\": url})] # 제품명 : 설화수, 가격 : 4,000원 이런 식으로 임베딩 하지 않은 애들을 넣는다 \n\n# page_content=\"구성성분 : 비타민\"\n\n    # for 한 화장품 단위 in 긁어모든 full 화장품 dataset:\n     # documents = [Document(page_content=text, metadata={\"source\": url})] # 제품명 : 설화수, 가격 : 4,000원 이런 식으로 임베딩 하지 않은 애들을 넣는다 \n\n    \n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1000,\n        chunk_overlap=200\n    )\n    splits = text_splitter.split_documents(documents)\n    \n    return splits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:35:50.787525Z","iopub.execute_input":"2025-01-23T06:35:50.787933Z","iopub.status.idle":"2025-01-23T06:35:50.795341Z","shell.execute_reply.started":"2025-01-23T06:35:50.787905Z","shell.execute_reply":"2025-01-23T06:35:50.794130Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"def create_vectorstore(splits): \n    vectorstore = Chroma.from_documents(documents=splits, embedding=hf_embeddings)\n    return vectorstore","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:35:55.195842Z","iopub.execute_input":"2025-01-23T06:35:55.196274Z","iopub.status.idle":"2025-01-23T06:35:55.201371Z","shell.execute_reply.started":"2025-01-23T06:35:55.196240Z","shell.execute_reply":"2025-01-23T06:35:55.200007Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"topic = \"흑백요리사\"\n# Load wikipedia documents for this topic\nsplits = load_Korean_wiki_docs(topic) \n# Create vectorstore with this fetched docs\nvectorstore = create_vectorstore(splits)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:35:57.530731Z","iopub.execute_input":"2025-01-23T06:35:57.531084Z","iopub.status.idle":"2025-01-23T06:35:57.985446Z","shell.execute_reply.started":"2025-01-23T06:35:57.531058Z","shell.execute_reply":"2025-01-23T06:35:57.984317Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"splits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:36:40.691085Z","iopub.execute_input":"2025-01-23T06:36:40.691475Z","iopub.status.idle":"2025-01-23T06:36:40.698967Z","shell.execute_reply.started":"2025-01-23T06:36:40.691441Z","shell.execute_reply":"2025-01-23T06:36:40.697469Z"}},"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"[Document(metadata={'source': 'https://ko.wikipedia.org/wiki/흑백요리사'}, page_content='《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《무명요리사》였다.[1]')]"},"metadata":{}}],"execution_count":77},{"cell_type":"code","source":"def create_rag_chain(vectorstore):\n    prompt_template = \"\"\"문맥을 참고하여 질문에 정확하고 간결하게 답하십시오.\n    문맥: {context}\n    질문: {question}\n    답변:\"\"\"\n    \n    PROMPT = PromptTemplate(\n        template=prompt_template, input_variables=[\"context\", \"question\"]\n    )\n\n    chain_type_kwargs = {\"prompt\": PROMPT}\n\n    # Make context shorter\n    # def short_context(context, max_length=300):\n    #     return context[:max_length] if len(context) > max_length else context\n    \n    # class ShortContextRetriever(BaseRetriever):\n    #     def __init__(self, retriever):\n    #         super().__init__()\n    #         self._retriever = retriever\n        \n    #     def get_relevant_documents(self, query):\n    #         docs = self._retriever.get_relevant_documents(query)\n    #         for doc in docs:\n    #             doc.page_content = short_context(doc.page_content)\n    #         return docs\n    \n    # retriever = ShortContextRetriever(vectorstore.as_retriever())\n\n    qa_chain = RetrievalQA.from_chain_type(\n        llm=hf_llm,\n        chain_type=\"stuff\",\n        retriever=vectorstore.as_retriever(),\n        chain_type_kwargs=chain_type_kwargs,\n        return_source_documents=True\n    )\n    \n    return qa_chain","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:36:00.275173Z","iopub.execute_input":"2025-01-23T06:36:00.275579Z","iopub.status.idle":"2025-01-23T06:36:00.281659Z","shell.execute_reply.started":"2025-01-23T06:36:00.275514Z","shell.execute_reply":"2025-01-23T06:36:00.280504Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"# create langchang RAG chain\nqa_chain = create_rag_chain(vectorstore)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:36:02.461149Z","iopub.execute_input":"2025-01-23T06:36:02.461514Z","iopub.status.idle":"2025-01-23T06:36:02.467081Z","shell.execute_reply.started":"2025-01-23T06:36:02.461485Z","shell.execute_reply":"2025-01-23T06:36:02.465855Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"docs = vectorstore.as_retriever().get_relevant_documents(question)\ndocs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:19:42.834184Z","iopub.execute_input":"2025-01-23T06:19:42.834616Z","iopub.status.idle":"2025-01-23T06:19:42.919318Z","shell.execute_reply.started":"2025-01-23T06:19:42.834578Z","shell.execute_reply":"2025-01-23T06:19:42.918091Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-41-ca9a4e50d709>:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n  docs = vectorstore.as_retriever().get_relevant_documents(question)\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"[Document(metadata={'source': 'https://ko.wikipedia.org/wiki/흑백요리사'}, page_content='《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《무명요리사》였다.[1]'),\n Document(metadata={'source': 'https://ko.wikipedia.org/wiki/흑백요리사'}, page_content='《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《무명요리사》였다.[1]'),\n Document(metadata={'source': 'https://ko.wikipedia.org/wiki/흑백요리사'}, page_content='《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《무명요리사》였다.[1]')]"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"docs = vectorstore.similarity_search(question, k=4)\ndocs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:19:49.962238Z","iopub.execute_input":"2025-01-23T06:19:49.962707Z","iopub.status.idle":"2025-01-23T06:19:50.046036Z","shell.execute_reply.started":"2025-01-23T06:19:49.962674Z","shell.execute_reply":"2025-01-23T06:19:50.044928Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"[Document(metadata={'source': 'https://ko.wikipedia.org/wiki/흑백요리사'}, page_content='《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《무명요리사》였다.[1]'),\n Document(metadata={'source': 'https://ko.wikipedia.org/wiki/흑백요리사'}, page_content='《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《무명요리사》였다.[1]'),\n Document(metadata={'source': 'https://ko.wikipedia.org/wiki/흑백요리사'}, page_content='《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《무명요리사》였다.[1]')]"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"# It seems vectorDB loading from embedding model works fine, but seems llm model does not.\n# Some Korean llm model seems to work fine in text-generation task, but for Question-Ansering task, we might need another approach.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:39:14.011795Z","iopub.execute_input":"2025-01-23T06:39:14.012151Z","iopub.status.idle":"2025-01-23T06:39:14.016895Z","shell.execute_reply.started":"2025-01-23T06:39:14.012125Z","shell.execute_reply":"2025-01-23T06:39:14.015404Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"## 2. Use QA pipeline with vectorstor similarity search¶","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:01:59.092636Z","iopub.execute_input":"2025-01-23T07:01:59.093092Z","iopub.status.idle":"2025-01-23T07:01:59.097815Z","shell.execute_reply.started":"2025-01-23T07:01:59.093057Z","shell.execute_reply":"2025-01-23T07:01:59.096275Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# import torch\nfrom transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n\n# Load model and tokenizer\nmodel_name = \"yjgwak/klue-bert-base-finetuned-squard-kor-v1\"\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Set Q_A pipeline\nqa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:39:23.284093Z","iopub.execute_input":"2025-01-23T06:39:23.284440Z","iopub.status.idle":"2025-01-23T06:39:37.004034Z","shell.execute_reply.started":"2025-01-23T06:39:23.284416Z","shell.execute_reply":"2025-01-23T06:39:37.002771Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/635 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"929c09101e094c3d880ac856a5c231e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fcc9cacda91457e99c8e61daf0be4f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/367 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47f4c9d547c243a9a13503e071591443"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/246k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"116fec6d961d42678a8c393e6f61a3fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67ad021a178549f2b927e3c82c237d23"}},"metadata":{}},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"# Example: define question and context \nquestion = \"오늘 날씨 어때?\"\ncontext = \"오늘의 날씨는 맑고 따뜻한 기온이 유지될 것으로 보입니다.\"\n\n# model chain\nresult = qa_pipeline(question=question, context=context)\n\n# Result\nprint(\"질문:\", question)\nprint(\"답변:\", result['answer'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:52:48.010076Z","iopub.execute_input":"2025-01-23T06:52:48.010627Z","iopub.status.idle":"2025-01-23T06:52:48.139908Z","shell.execute_reply.started":"2025-01-23T06:52:48.010581Z","shell.execute_reply":"2025-01-23T06:52:48.138053Z"}},"outputs":[{"name":"stdout","text":"질문: 오늘 날씨 어때?\n답변: 맑고 따뜻한 기온이\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"# search context in VectorStore\ndef retrieve_context(question, vectorstore):\n    docs = vectorstore.similarity_search(question, k=4)\n    if docs:\n        return \" \".join([doc.page_content for doc in docs])\n        # return docs[0].page_content  # return first relevant doc\n    else:\n        return None\n\n# Generate answer based on query and searched context similar to RAG chain\ndef answer_question_with_context(question, vectorstore):\n    context = retrieve_context(question, vectorstore)\n    if context:\n        result = qa_pipeline(question=question, context=context)\n        return result['answer'], context  # return answer and used source doc\n    else:\n        return \"관련 문맥을 찾지 못했습니다.\", None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:52:52.968836Z","iopub.execute_input":"2025-01-23T06:52:52.969222Z","iopub.status.idle":"2025-01-23T06:52:52.975832Z","shell.execute_reply.started":"2025-01-23T06:52:52.969192Z","shell.execute_reply":"2025-01-23T06:52:52.974284Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"# Example\nquestion = \"심사위원을 누가 맡았어?\"\n\nanswer, used_context = answer_question_with_context(question, vectorstore)\n\nprint(\"질문:\", question)\nprint(\"답변:\", answer)\nprint(\"사용된 문맥:\", used_context)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:52:58.913430Z","iopub.execute_input":"2025-01-23T06:52:58.913934Z","iopub.status.idle":"2025-01-23T06:53:00.085226Z","shell.execute_reply.started":"2025-01-23T06:52:58.913901Z","shell.execute_reply":"2025-01-23T06:53:00.083905Z"}},"outputs":[{"name":"stdout","text":"질문: 심사위원을 누가 맡았어?\n답변: 백종원과 안성재가\n사용된 문맥: 《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《무명요리사》였다.[1] 《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《무명요리사》였다.[1] 《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《무명요리사》였다.[1] 《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《무명요리사》였다.[1]\n","output_type":"stream"}],"execution_count":86},{"cell_type":"code","source":"# It seems the best and simple and cost-free option when OpenAI api cannot be used.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:55:31.195887Z","iopub.execute_input":"2025-01-23T06:55:31.196275Z","iopub.status.idle":"2025-01-23T06:55:31.201376Z","shell.execute_reply.started":"2025-01-23T06:55:31.196249Z","shell.execute_reply":"2025-01-23T06:55:31.200122Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"## 3. Use Gemini+RAG","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:02:21.351002Z","iopub.execute_input":"2025-01-23T07:02:21.351447Z","iopub.status.idle":"2025-01-23T07:02:21.357008Z","shell.execute_reply.started":"2025-01-23T07:02:21.351417Z","shell.execute_reply":"2025-01-23T07:02:21.355717Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"pip install -q langchain langchain-community langchain_huggingface chromadb google-generativeai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:26:47.298473Z","iopub.execute_input":"2025-01-23T07:26:47.298926Z","iopub.status.idle":"2025-01-23T07:26:52.442642Z","shell.execute_reply.started":"2025-01-23T07:26:47.298891Z","shell.execute_reply":"2025-01-23T07:26:52.440944Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"from langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import Chroma\nfrom langchain.schema import Document\nfrom langchain.llms import OpenAI\nimport google.generativeai as genai\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:27:04.930182Z","iopub.execute_input":"2025-01-23T07:27:04.930737Z","iopub.status.idle":"2025-01-23T07:27:05.464273Z","shell.execute_reply.started":"2025-01-23T07:27:04.930694Z","shell.execute_reply":"2025-01-23T07:27:05.463073Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"YOUR-API-KEY\"\ngenai_api_key = \"YOUR-API-KEY\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:27:10.935479Z","iopub.execute_input":"2025-01-23T07:27:10.936011Z","iopub.status.idle":"2025-01-23T07:27:10.941511Z","shell.execute_reply.started":"2025-01-23T07:27:10.935979Z","shell.execute_reply":"2025-01-23T07:27:10.939923Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"genai.configure(api_key=genai_api_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:27:26.912189Z","iopub.execute_input":"2025-01-23T07:27:26.912620Z","iopub.status.idle":"2025-01-23T07:27:26.918370Z","shell.execute_reply.started":"2025-01-23T07:27:26.912582Z","shell.execute_reply":"2025-01-23T07:27:26.916811Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"pip install genai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:27:12.674007Z","iopub.execute_input":"2025-01-23T07:27:12.674362Z","iopub.status.idle":"2025-01-23T07:27:17.157665Z","shell.execute_reply.started":"2025-01-23T07:27:12.674337Z","shell.execute_reply":"2025-01-23T07:27:17.156391Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: genai in /usr/local/lib/python3.10/dist-packages (2.1.0)\nRequirement already satisfied: ipython<9.0.0,>=8.10.0 in /usr/local/lib/python3.10/dist-packages (from genai) (8.31.0)\nRequirement already satisfied: openai<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from genai) (0.27.10)\nRequirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from genai) (0.9.0)\nRequirement already satisfied: tiktoken<0.4.0,>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from genai) (0.3.3)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (4.4.2)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (1.2.2)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (0.19.2)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (4.9.0)\nRequirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (3.0.48)\nRequirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (2.18.0)\nRequirement already satisfied: stack_data in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (0.6.3)\nRequirement already satisfied: traitlets>=5.13.0 in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (5.14.3)\nRequirement already satisfied: typing_extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (4.12.2)\nRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai<0.28.0,>=0.27.0->genai) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai<0.28.0,>=0.27.0->genai) (4.67.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai<0.28.0,>=0.27.0->genai) (3.11.10)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.4.0,>=0.3.2->genai) (2024.11.6)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython<9.0.0,>=8.10.0->genai) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython<9.0.0,>=8.10.0->genai) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython<9.0.0,>=8.10.0->genai) (0.2.13)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->genai) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->genai) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->genai) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->genai) (2024.12.14)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (1.18.3)\nRequirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython<9.0.0,>=8.10.0->genai) (2.2.0)\nRequirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython<9.0.0,>=8.10.0->genai) (3.0.0)\nRequirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython<9.0.0,>=8.10.0->genai) (0.2.3)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":75},{"cell_type":"code","source":"# 1. Gemini model\ngemini_model = genai.GenerativeModel('gemini-1.5-flash')\n\n# 2. embedding model\nembedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:27:43.271781Z","iopub.execute_input":"2025-01-23T07:27:43.272160Z","iopub.status.idle":"2025-01-23T07:27:47.051104Z","shell.execute_reply.started":"2025-01-23T07:27:43.272134Z","shell.execute_reply":"2025-01-23T07:27:47.050126Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-77-5839f8a42bf5>:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"from langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.schema import Document\n\n# Sample documents\ndocs = [\n    Document(page_content=\"한국어 챗봇은 자연어 처리 기술을 사용하여 사용자와 대화를 나눕니다.\", metadata={\"source\": \"doc1\"}),\n    Document(page_content=\"인공지능을 활용한 챗봇은 여러 산업에서 사용되고 있습니다.\", metadata={\"source\": \"doc2\"}),\n    Document(page_content=\"한국어와 영어를 동시에 지원하는 챗봇이 점점 늘어나고 있습니다.\", metadata={\"source\": \"doc3\"}),\n    Document(page_content=\"챗봇은 고객 서비스를 개선하고 사용자 경험을 향상시키는 데 중요한 역할을 합니다.\", metadata={\"source\": \"doc4\"})\n]\n\n# 텍스트 분할기 생성\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n\n# 문서를 분할\nsplits = text_splitter.split_documents(docs)\n\n# Embedding 모델 설정 (이미 잘 설정되어 있다고 가정)\nembedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n\n# Chroma DB 생성 (새로운 디렉토리에 저장)\npersist_directory = \"./new_chroma_db\"\nvectorstore = Chroma.from_documents(docs, embedding=embedding_model, persist_directory=persist_directory)\n\n# 정상적으로 vectorstore 생성되었음을 출력\nprint(\"Vectorstore created successfully!\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:38:19.847929Z","iopub.execute_input":"2025-01-23T07:38:19.848343Z","iopub.status.idle":"2025-01-23T07:38:22.989860Z","shell.execute_reply.started":"2025-01-23T07:38:19.848310Z","shell.execute_reply":"2025-01-23T07:38:22.988522Z"}},"outputs":[{"name":"stdout","text":"Vectorstore created successfully!\n","output_type":"stream"}],"execution_count":93},{"cell_type":"code","source":"# RAG using prompt\ndef rag_chatbot(question):\n    context_doc = vectorstore.similarity_search(question, k=1)\n   # context = context_doc[0].page_content if context_doc else \"정보를 찾을 수 없습니다.\"\n\n    context = \" \".join([doc.page_content for doc in context_doc])\n\n    prompt = f\"Context: {context}\\nQuestion: {question}\\n한문장으로 대답해줘:\"\n    # response = gemini_model(prompt)\n    \n    response = gemini_model.generate_content(prompt)\n    answer = response.candidates[0].content.parts[0].text\n\n    # print(\"출처 문서:\", context)\n    return answer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:40:31.007285Z","iopub.execute_input":"2025-01-23T07:40:31.007836Z","iopub.status.idle":"2025-01-23T07:40:31.014865Z","shell.execute_reply.started":"2025-01-23T07:40:31.007798Z","shell.execute_reply":"2025-01-23T07:40:31.013464Z"}},"outputs":[],"execution_count":99},{"cell_type":"code","source":"# sample question\nquestion = \"영등포 근처에 IT 관련 배울 수 있는 학원이 있니? 있으면 구체적으로 이름 좀 알려줘\"\nresponse = rag_chatbot(question)\n\nprint(\"질문:\", question)\nprint(\"답변:\", response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:51:43.638626Z","iopub.execute_input":"2025-01-23T07:51:43.639070Z","iopub.status.idle":"2025-01-23T07:51:44.372795Z","shell.execute_reply.started":"2025-01-23T07:51:43.639041Z","shell.execute_reply":"2025-01-23T07:51:44.371700Z"}},"outputs":[{"name":"stdout","text":"질문: 영등포 근처에 IT 관련 배울 수 있는 학원이 있니? 있으면 구체적으로 이름 좀 알려줘\n답변: 네, 영등포 근처에는 코딩 관련 학원인 [학원 이름 1], [학원 이름 2] 등이 있으며,  자세한 정보는 각 학원 웹사이트에서 확인 가능합니다.\n\n","output_type":"stream"}],"execution_count":103},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}